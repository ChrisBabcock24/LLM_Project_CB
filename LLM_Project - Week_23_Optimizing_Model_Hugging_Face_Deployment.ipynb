{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio datasets evaluate transformers rouge_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "from transformers import (AutoModelForSeq2SeqLM, AutoTokenizer,\n",
    "                          Trainer, TrainingArguments, DataCollatorForSeq2Seq,\n",
    "                          get_linear_schedule_with_warmup)\n",
    "import numpy as np\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ROUGE metric\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = load_dataset('csv', data_files='preprocessed_train.csv')['train']\n",
    "test_dataset = load_dataset('csv', data_files='preprocessed_test.csv')['train']\n",
    "\n",
    "# Filter empty documents\n",
    "train_dataset = train_dataset.filter(lambda x: x['document'] and len(x['document']) > 0)\n",
    "test_dataset = test_dataset.filter(lambda x: x['document'] and len(x['document']) > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and tokenizer\n",
    "model_name = \"facebook/bart-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization Function\n",
    "def make_tokenize_function(tokenizer):\n",
    "    def tokenize_function(examples):\n",
    "        inputs = examples['document']\n",
    "        labels = examples['summary']\n",
    "        \n",
    "        model_inputs = tokenizer(inputs, padding='max_length', truncation=True, max_length=64)\n",
    "        \n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(labels, padding='max_length', truncation=True, max_length=32)\n",
    "\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        return model_inputs\n",
    "    \n",
    "    return tokenize_function\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenization_fn = make_tokenize_function(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize datasets\n",
    "train_dataset = train_dataset.map(tokenization_fn, batched=True, remove_columns=['summary'], num_proc=4)\n",
    "test_dataset = test_dataset.map(tokenization_fn, batched=True, remove_columns=['summary'], num_proc=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric computation\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]  # Get the logits\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions.argmax(axis=-1).tolist(), skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels.tolist(), skip_special_tokens=True)\n",
    "\n",
    "    # Calculate ROUGE scores\n",
    "    rouge_results = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    return {\n",
    "        \"rouge1\": rouge_results[\"rouge1\"],\n",
    "        \"rouge2\": rouge_results[\"rouge2\"],\n",
    "        \"rougeL\": rouge_results[\"rougeL\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"Chribabc/LLM_Project_Lighthouse\"  # Hugging Face username and repo name\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='D:\\\\Documents\\\\GitHub\\\\LLM-Project\\\\My_Model',  # Local path\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=repo_name,  #repo name for pushing\n",
    "    evaluation_strategy=\"no\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.02,\n",
    "    logging_dir='D:\\\\Documents\\\\GitHub\\\\LLM-Project\\\\Logs',\n",
    "    logging_steps=500,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=2,\n",
    "    max_grad_norm=1.0,  # Add gradient clipping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to the appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Clear cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track best model\n",
    "best_rouge1 = 0\n",
    "best_model_path = \"D:\\\\Documents\\\\GitHub\\\\LLM-Project\\\\best_model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chunk sizes\n",
    "train_chunk_size = 4000  # Set chunk size for training\n",
    "num_train_chunks = len(train_dataset) // train_chunk_size + (len(train_dataset) % train_chunk_size > 0)\n",
    "\n",
    "# Training loop\n",
    "for chunk_idx in range(num_train_chunks):\n",
    "    start_idx = chunk_idx * train_chunk_size\n",
    "    end_idx = min(start_idx + train_chunk_size, len(train_dataset))\n",
    "\n",
    "    chunk_train_dataset = train_dataset.select(range(start_idx, end_idx))\n",
    "\n",
    "    print(f\"Training chunk {chunk_idx + 1}/{num_train_chunks}...\")\n",
    "\n",
    "    # Define the optimizer for the current chunk\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=training_args.learning_rate)\n",
    "\n",
    "    # Define total training steps and scheduler for the current chunk\n",
    "    total_steps = len(chunk_train_dataset) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "    warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "    # Initialize the scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    # Start training for this chunk\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=chunk_train_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        optimizers=(optimizer, scheduler),  # Pass the optimizer and scheduler\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Clear memory after training the chunk\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunked evaluation\n",
    "eval_chunk_size = 50  # Set smaller chunk size for evaluation\n",
    "num_eval_chunks = len(test_dataset) // eval_chunk_size + (len(test_dataset) % eval_chunk_size > 0)\n",
    "\n",
    "for chunk_idx in range(num_eval_chunks):\n",
    "    start_idx = chunk_idx * eval_chunk_size\n",
    "    end_idx = min(start_idx + eval_chunk_size, len(test_dataset))\n",
    "\n",
    "    chunk_eval_dataset = test_dataset.select(range(start_idx, end_idx))\n",
    "\n",
    "    # Print current evaluation chunk\n",
    "    print(f\"Evaluating chunk {chunk_idx + 1}/{num_eval_chunks}...\")\n",
    "\n",
    "    # Evaluate on the current chunk\n",
    "    eval_results = trainer.evaluate(eval_dataset=chunk_eval_dataset)\n",
    "\n",
    "    # Print the evaluation results to debug\n",
    "    print(\"Evaluation Results:\", eval_results)  # Check the output structure\n",
    "\n",
    "    # Check if this model is better\n",
    "    if 'rouge1' in eval_results and eval_results['rouge1'] > best_rouge1:\n",
    "        best_rouge1 = eval_results['rouge1']\n",
    "        model.save_pretrained(best_model_path)  # Save the best model\n",
    "        print(f\"New best model saved with ROUGE-1: {best_rouge1}\")\n",
    "\n",
    "    # Clear memory after evaluation of the chunk\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push model to Hugging Face\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model and tokenizer\n",
    "model.save_pretrained(\"D:\\\\Documents\\\\GitHub\\\\LLM-Project\\\\My_Model\")\n",
    "tokenizer.save_pretrained(\"D:\\\\Documents\\\\GitHub\\\\LLM-Project\\\\My_Model\")\n",
    "\n",
    "# Output best model information\n",
    "print(f\"Best model saved at: {best_model_path} with ROUGE-1: {best_rouge1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
